//
// Created by user on 01.02.2023.
//
#include <boost/asio/post.hpp>
#include <windows.h>
#include <iostream>
#include <ranges>
#include <filesystem>
#include <chrono>
#include <algorithm>
#include <thread>
#include <atomic>
#include <fstream>
#include <mutex>
#include "InvertedIndex.h"
#include <codecvt>
#include <boost/algorithm/string.hpp>
#include "simd_tokenizer.h"
#include "OEMFastTokenizer.h"
#include "Interface.h"
#include <future>
#include <psapi.h>


#include <boost/asio/awaitable.hpp>
#include <boost/asio/use_awaitable.hpp>

#include <boost/asio/as_tuple.hpp>


static size_t process_memory()
{
    PROCESS_MEMORY_COUNTERS_EX pmc{};
    GetProcessMemoryInfo(GetCurrentProcess(),
                         reinterpret_cast<PROCESS_MEMORY_COUNTERS*>(&pmc),
                         sizeof(pmc));
    return pmc.WorkingSetSize;   // –±–∞–π—Ç—ã
}

void inverted_index::InvertedIndex::pingIo(boost::asio::io_context& ctx, const char* name)
{
    inverted_index::InvertedIndex::addToLog(std::string("PING post -> ") + name);
    boost::asio::post(ctx, [name]{
        inverted_index::InvertedIndex::addToLog(std::string("PING executed <- ") + name);
    });
}


void inverted_index::InvertedIndex::commitSingleWord(const PostingTask& t)
{
    const uint32_t wid        = t.wordId;
    const size_t   chunkIndex = wid / CHUNK_SIZE;
    const size_t   localIndex = wid % CHUNK_SIZE;

    // —Å–æ–∑–¥–∞—ë–º/—Ä–∞—Å—à–∏—Ä—è–µ–º —á–∞–Ω–∫ –ø–æ–¥ –≥–ª–æ–±–∞–ª—å–Ω—ã–º –º—å—é—Ç–µ–∫—Å–æ–º, –∫–∞–∫ –≤ getPostingList
    {
        std::lock_guard<std::mutex> g(mapMutex);
        if (chunkIndex >= dictionaryChunks.size())
            dictionaryChunks.resize(chunkIndex + 1);
        if (!dictionaryChunks[chunkIndex])
            dictionaryChunks[chunkIndex] = std::make_unique<Chunk>();
    }

    Chunk& chunk = *dictionaryChunks[chunkIndex];

    std::unique_lock<std::shared_mutex> lk(chunk.mutex);
    chunk.bucket[localIndex][t.fileId] += t.count;
}

void inverted_index::InvertedIndex::commitChunkMap(
        const std::unordered_map<size_t, std::vector<PostingTask>>& chunkMap)
{
    // === 1. (–†–µ–¥–∫–æ) —Ä–∞—Å—à–∏—Ä—è–µ–º –º–∞—Å—Å–∏–≤ —á–∞–Ω–∫–æ–≤ –û–î–ò–ù —Ä–∞–∑ ===
    {
        std::lock_guard<std::mutex> g(mapMutex);

        size_t maxIndex = 0;
        for (auto& [cid, _] : chunkMap)
            if (cid > maxIndex) maxIndex = cid;

        if (maxIndex >= dictionaryChunks.size())
            dictionaryChunks.resize(maxIndex + 1);

        for (auto& [cid, _] : chunkMap)
            if (!dictionaryChunks[cid])
                dictionaryChunks[cid] = std::make_unique<Chunk>();
    }

    // === 2. –û–±–Ω–æ–≤–ª—è–µ–º —á–∞–Ω–∫–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ lock ===
    for (auto& [cid, tasks] : chunkMap)
    {
        Chunk& ch = *dictionaryChunks[cid];
        std::unique_lock<std::shared_mutex> lk(ch.mutex);

        for (auto& t : tasks)
        {
            size_t local = t.wordId % CHUNK_SIZE;
            ch.bucket[local][t.fileId] += t.count;
        }
    }
}


void inverted_index::InvertedIndex::processBatch(const PostingBatch& batch)
{
    try
    {
        if (batch.list.empty())
        {
            if (batch.promise)
                batch.promise->set_value();
            return;
        }

        // 1. LOCAL MAP: wordId ‚Üí count
        robin_hood::unordered_map<uint32_t, uint32_t> widMap;
        widMap.reserve(batch.list.size());

        // 1.1. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞ ‚Üí wid + —Å—É–º–º–∏—Ä—É–µ–º counts
        for (auto& [word, count] : batch.list)
        {
            uint32_t wid = wordIds.getId(word);
            widMap[wid] += count;

            // wordRefs –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∑–¥–µ—Å—å (–≤ strand!)
            auto& refv = wordRefs[batch.fileId];
            if (refv.empty() || refv.back() != wid)
                refv.push_back(wid);
        }

        // 2. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ chunkId
        std::unordered_map<size_t, std::vector<PostingTask>> chunkMap;
        chunkMap.reserve(widMap.size());

        for (auto& [wid, count] : widMap)
        {
            size_t chunkIndex = wid / CHUNK_SIZE;
            chunkMap[chunkIndex].push_back({ batch.fileId, wid, count });
        }

        // 3. –û–¥–∏–Ω commit-task –≤ io_commit
        boost::asio::post(io_commit_, [this,
                chunkMap = std::move(chunkMap),
                promise = batch.promise]()
        {
            try
            {
                commitChunkMap(chunkMap);
                if (promise) promise->set_value();
            }
            catch (const std::exception& e)
            {
                addToLog(std::string("io_commit handler exception: ") + e.what());
                if (promise) { try { promise->set_exception(std::current_exception()); } catch (...) {} }
            }
            catch (...)
            {
                addToLog("io_commit handler unknown exception");
                if (promise) { try { promise->set_exception(std::current_exception()); } catch (...) {} }
            }
        });

    }
    catch (...)
    {
        if (batch.promise)
            batch.promise->set_exception(std::current_exception());
    }
}


// –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫: –∫–æ–ø–∏—Ä—É–µ—Ç posting-–ª–∏—Å—Ç —Å–ª–æ–≤–∞
std::optional<PostingList> inverted_index::InvertedIndex::getPostingCopyByWord(const std::string& w) const
{
    uint32_t wid;
    if (!wordIds.tryGet(w, wid))
        return std::nullopt;

    const size_t chunkIndex = wid / CHUNK_SIZE;
    const size_t localIndex = wid % CHUNK_SIZE;

    if (chunkIndex >= dictionaryChunks.size())
        return std::nullopt;

    const auto& chunkPtr = dictionaryChunks[chunkIndex];
    if (!chunkPtr)
        return std::nullopt;

    std::shared_lock<std::shared_mutex> lk(chunkPtr->mutex);
    const PostingList& pl = chunkPtr->bucket[localIndex];
    if (pl.empty())
        return std::nullopt;

    return pl; // –∫–æ–ø–∏—è
}


void inverted_index::InvertedIndex::applyBatchInStrand(PostingBatch batch)
{
    // –í–ê–ñ–ù–û: —Ä–µ–∞–ª—å–Ω—ã–π commit –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å—Ç—Ä–æ–≥–æ –≤ strand_,
    // —á—Ç–æ–±—ã –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å dictionary/wordRefs –±—ã–ª–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã.
    boost::asio::post(strand_, [this, batch = std::move(batch)]() mutable
    {
        try {

            processBatch(batch);
        }
        catch (const std::exception& e) {
            addToLog(std::string{"applyBatchInStrand: exception: "} + e.what());
        }
        catch (...) {
            addToLog("applyBatchInStrand: unknown exception");
        }
    });
}

void inverted_index::InvertedIndex::delFromDictionary(const std::vector<FileId>& list)
{
    boost::asio::post(strand_, [this, list]() {
        for (FileId fileId : list)
            safeEraseFile(fileId);   // —Ç–µ–ø–µ—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ commit-–ø–æ—Ç–æ–∫–µ
    });
}


void inverted_index::InvertedIndex::safeEraseFileInternal(FileId fileId)
{
    // –ï—Å–ª–∏ –µ—Å—Ç—å wordRefs ‚Äî –∏–¥—ë–º —Ç–æ–ª—å–∫–æ –ø–æ –Ω—É–∂–Ω—ã–º wid
    auto itRefs = wordRefs.find(fileId);
    if (itRefs != wordRefs.end())
    {
        const auto& widList = itRefs->second;
        for (uint32_t wid : widList)
        {
            size_t chunkIndex = wid / CHUNK_SIZE;
            size_t localIndex = wid % CHUNK_SIZE;

            if (chunkIndex >= dictionaryChunks.size())
                continue;

            auto& chunkPtr = dictionaryChunks[chunkIndex];
            if (!chunkPtr)
                continue;

            Chunk& chunk = *chunkPtr;
            std::unique_lock<std::shared_mutex> lk(chunk.mutex);
            auto& posting = chunk.bucket[localIndex];
            if (!posting.empty())
                posting.erase(fileId);
        }

        wordRefs.erase(itRefs);
    }
    else
    {
        // fallback: –ø–æ–ª–Ω—ã–π –æ–±—Ö–æ–¥ (—Ä–µ–¥–∫–∏–π —Å–ª—É—á–∞–π)
        for (auto& chunkPtr : dictionaryChunks)
        {
            if (!chunkPtr) continue;
            Chunk& chunk = *chunkPtr;

            std::unique_lock<std::shared_mutex> lk(chunk.mutex);
            for (auto& posting : chunk.bucket)
            {
                if (!posting.empty())
                    posting.erase(fileId);
            }
        }
    }

    addToLog("safeEraseFileInternal: removed fileId=" + std::to_string(fileId));
}




void logIndexError(const std::wstring& path, const std::string& msg)
{
    static std::mutex mtx;
    std::lock_guard<std::mutex> lock(mtx);

    std::ofstream out("index_errors.log", std::ios::app);
    if (!out) return;

    out << my::utf8(path) << " | " << msg << '\n';
}



std::future<void> inverted_index::InvertedIndex::updateDocumentBase(
        const std::vector<std::wstring>& vecPaths)
{
    addToLog("updateDocumentBase() ‚Üí start");
    work = true;

    // 1. diff
    UpdatePack pack = docPaths.getUpdate({ vecPaths.begin(), vecPaths.end() });

    std::vector<FileId> toDelete = pack.removed;
    toDelete.insert(toDelete.end(), pack.updated.begin(), pack.updated.end());

    std::vector<FileId> toIndex = pack.added;
    toIndex.insert(toIndex.end(), pack.updated.begin(), pack.updated.end());

    std::ostringstream diffLog;
    diffLog << "diff: +"  << pack.added.size()
            << ", upd "   << pack.updated.size()
            << ", del "   << pack.removed.size();
    addToLog(diffLog.str());

    // –ù–µ—Ç —Ä–∞–±–æ—Ç—ã ‚Äî —Å—Ä–∞–∑—É –≥–æ—Ç–æ–≤—ã–π future
    if (toDelete.empty() && toIndex.empty())
    {
        work = false;
        std::promise<void> p;
        p.set_value();
        return p.get_future();
    }

    // 2. –æ–±—â–∏–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–∏—Å
    auto finalPromise = std::make_shared<std::promise<void>>();
    std::future<void> future = finalPromise->get_future();

    // 3. –≤—Å—ë –æ—Å–Ω–æ–≤–Ω–æ–µ ‚Äî –≤ strand_
    boost::asio::post(
            strand_,
            [this,
                    toDelete = std::move(toDelete),
                    toIndex  = std::move(toIndex),
                    finalPromise]() mutable
            {
                // ---- –£–î–ê–õ–ï–ù–ò–ï ----
                for (FileId fileId : toDelete)
                {
                    try {
                        safeEraseFileInternal(fileId);
                    }
                    catch (...) {
                        addToLog("Exception in safeEraseFileInternal");
                    }
                }
                addToLog("updateDocumentBase: deletions done");

                // ---- –ò–ù–î–ï–ö–°–ê–¶–ò–Ø ----
                //std::vector<std::future<void>> fileFutures;


                std::vector<FileFuture> fileFutures;
                fileFutures.reserve(toIndex.size());

                for (FileId fileId : toIndex)
                {
                    auto p = std::make_shared<std::promise<void>>();

                    fileFutures.push_back({
                                                  fileId,
                                                  docPaths.pathById(fileId), // –∑–¥–µ—Å—å —Ç—ã –µ—â—ë –≤ strand_ ‚Üí –±–µ–∑–æ–ø–∞—Å–Ω–æ
                                                  p->get_future()
                                          });


                    boost::asio::post(
                            io_,
                            [this, fileId, p]()
                            {
                                try {

                                    fileIndexing(fileId, p);
                                }
                                catch (...) {
                                    try { p->set_exception(std::current_exception()); } catch (...) {}
                                }
                            });
                }

                addToLog("updateDocumentBase: indexing tasks dispatched, files=" +
                         std::to_string(fileFutures.size()));

                // ---- –û–ñ–ò–î–ê–ù–ò–ï –í–°–ï–• fileIndexing –í –û–¢–î–ï–õ–¨–ù–û–ú –ü–û–¢–û–ö–ï ----
                std::thread(
                        [this,
                                fileFutures = std::move(fileFutures),
                                finalPromise]() mutable
                        {
                            addToLog("updateDocumentBase: wait promises thread start");

                            for (auto& ff : fileFutures)
                            {
                                using namespace std::chrono_literals;

                                if (ff.fut.wait_for(60s) != std::future_status::ready)
                                {
                                    logIndexError(ff.path, "TIMEOUT waiting file future (60s)");
                                    continue; // –∏–ª–∏ break; –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –∞–≤–∞—Ä–∏–π–Ω–æ –∑–∞–≤–µ—Ä—à–∞—Ç—å –≤–µ—Å—å –∞–ø–¥–µ–π—Ç
                                }

                                try { ff.fut.get(); }
                                catch (const std::exception& e) { logIndexError(ff.path, e.what()); }
                                catch (...) { logIndexError(ff.path, "unknown exception"); }


                            }


                            addToLog("updateDocumentBase: all fileIndexing done");

                            // –§–∏–Ω–∞–ª—å–Ω—ã–π —à–∞–≥ ‚Äî –≤ strand_ (—Ç–∞–º –∂–µ –∂–∏–≤—É—Ç –≤—Å–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–Ω–¥–µ–∫—Å–∞)
                            boost::asio::post(
                                    strand_,
                                    [this, finalPromise]()
                                    {
                                        addToLog("FINAL: entered");

                                        try
                                        {
                                            addToLog("FINAL: before saveIndex");
                                            saveIndex();
                                            addToLog("FINAL: after saveIndex");

                                            work = false;

                                            addToLog("FINAL: before set_value");
                                            finalPromise->set_value();
                                            addToLog("FINAL: after set_value");
                                        }
                                        catch (const std::exception& e)
                                        {
                                            addToLog(std::string("FINAL: exception: ") + e.what());
                                            try { finalPromise->set_exception(std::current_exception()); } catch(...) {}
                                        }
                                        catch (...)
                                        {
                                            addToLog("FINAL: unknown exception");
                                            try { finalPromise->set_exception(std::current_exception()); } catch(...) {}
                                        }
                                    });

                        }).detach();
            });

    return future;
}



void logIndexingDebug(const std::string& msg) {
    static std::mutex logMutex;
    std::lock_guard<std::mutex> lock(logMutex);
    std::ofstream log("indexing_debug.log", std::ios::app);
    log.imbue(std::locale("Russian_Russia.866"));
    log << msg << std::endl;
}

void inverted_index::InvertedIndex::fileIndexing(
        FileId fileId,
        std::shared_ptr<std::promise<void>> promise)
{
    try
    {
        using convert_t = std::codecvt_utf8<wchar_t>;
        std::wstring_convert<convert_t, wchar_t> strconverter;

        std::wstring fullPath = docPaths.pathById(fileId); // –ö–û–ü–ò–Ø!

        std::ifstream file(fullPath.c_str(), std::ios::binary);
        if (!file.is_open())
        {
            addToLog("fileIndexing: cannot open file " +
                     strconverter.to_bytes(fullPath));

            promise->set_exception(
                    std::make_exception_ptr(
                            std::runtime_error("file not found")));
            return;
        }

        // --- —Å–ª–æ–≤–∞—Ä—å —á–∞—Å—Ç–æ—Ç ---
        robin_hood::unordered_map<std::string, size_t> freqWordFile;

        // --- SIMD tokenizer ---
        static const size_t BUF_SIZE = 64 * 1024;
        std::vector<char> buf(BUF_SIZE);

        std::string carry;   // —Ö–≤–æ—Å—Ç —Å–ª–æ–≤–∞ –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–∞—Ö –±—É—Ñ–µ—Ä–æ–≤

        while (true)
        {
            file.read(buf.data(), BUF_SIZE);
            std::size_t readBytes = file.gcount();
            if (readBytes == 0)
                break;

            const bool isLastChunk = file.eof();

            simd_tokenizer::tokenize_oem866_buffer(
                    buf.data(),
                    readBytes,
                    isLastChunk,
                    carry,
                    [&](std::string_view tok)
                    {
                        // -------- üî• –¢–í–û–Ø OEM-–õ–û–ì–ò–ö–ê --------

                        std::string w;
                        w.assign(tok.data(), tok.size());  // –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º std::string(tok)

                        OEMFastTokenizer::normalizeToken(w);

                        if (!w.empty())
                            ++freqWordFile[w];
                    });
        }

        // —Å–æ–∑–¥–∞—ë–º batch
        PostingBatch batch;
        batch.fileId = fileId;
        batch.promise = promise;

        batch.list.reserve(freqWordFile.size());
        for (auto &[word, count] : freqWordFile)
            batch.list.emplace_back(word, count);

        applyBatchInStrand(std::move(batch));
    }
    catch (...)
    {
        addToLog("fileIndexing: EXCEPTION for fileId=" + std::to_string(fileId));
        try { promise->set_exception(std::current_exception()); }
        catch (...) {}
    }
}


void inverted_index::InvertedIndex::addToLog(const string& _s) {

    /**
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –ª–æ–≥-—Ñ–∞–π–ª*/

    char dataTime[20];
    time_t now = time(nullptr);
    struct tm tm_buf{};
#ifdef _WIN32
    localtime_s(&tm_buf, &now);
#else
    localtime_r(&now, &tm_buf);
#endif
    strftime(dataTime, sizeof(dataTime), "%H:%M:%S %Y-%m-%d", &tm_buf);


  //  lock_guard<mutex> myLock(logMutex);

    ofstream logFile;
    std::stringstream ss;
    ss << std::this_thread::get_id();
    uint64_t tid = std::stoull(ss.str());

    logFile.open("index_log"+ std::to_string(tid)  +".log", ios::app);
    logFile << "[" << dataTime << "] " << _s << endl;
    logFile.close();

}

PostingList inverted_index::InvertedIndex::getWordCount(const std::string& word)
{
    if (auto opt = getPostingCopyByWord(word))
        return *opt;
    return {};
}

void inverted_index::InvertedIndex::dictonaryToLog() const {
    // for(const auto& i:dictionary)
    //      addToLog(i.first + "\t" + std::to_string(i.second.size()));
}

void inverted_index::InvertedIndex::rebuildDictionaryFromChunks()
{
    std::lock_guard<std::mutex> g(mapMutex);
    dictionary.clear();
    dictionary.reserve(dictionaryChunks.size() * CHUNK_SIZE);

    for (const auto & chunkPtr : dictionaryChunks)
    {
        if (!chunkPtr) {
            // –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ posting-–ª–∏—Å—Ç—ã
            for (size_t i=0; i<CHUNK_SIZE; ++i)
                dictionary.emplace_back();
            continue;
        }

        Chunk& chunk = *chunkPtr;
        std::shared_lock<std::shared_mutex> lk(chunk.mutex);


        for (size_t localIndex = 0; localIndex < CHUNK_SIZE; ++localIndex)
            dictionary.push_back(chunk.bucket[localIndex]);
    }
}

void inverted_index::InvertedIndex::rebuildChunksFromDictionary()
{
    dictionaryChunks.clear();

    for (size_t wid = 0; wid < dictionary.size(); ++wid)
    {
        size_t chunkIndex = wid / CHUNK_SIZE;
        size_t localIndex = wid % CHUNK_SIZE;

        if (chunkIndex >= dictionaryChunks.size())
            dictionaryChunks.resize(chunkIndex + 1);

        if (!dictionaryChunks[chunkIndex])
            dictionaryChunks[chunkIndex] = std::make_unique<Chunk>();

        dictionaryChunks[chunkIndex]->bucket[localIndex] = dictionary[wid];
    }
}




void inverted_index::InvertedIndex::reconstructWordIts()
{
    wordRefs.clear();

    for (size_t chunkIndex = 0; chunkIndex < dictionaryChunks.size(); ++chunkIndex)
    {
        const auto& chunkPtr = dictionaryChunks[chunkIndex];
        if (!chunkPtr) continue;

        Chunk& chunk = *chunkPtr;
        std::shared_lock<std::shared_mutex> lk(chunk.mutex);

        for (size_t localIndex = 0; localIndex < chunk.bucket.size(); ++localIndex)
        {
            const PostingList& posting = chunk.bucket[localIndex];
            if (posting.empty()) continue;

            uint32_t wid = static_cast<uint32_t>(chunkIndex * CHUNK_SIZE + localIndex);

            for (const auto& [docId, cnt] : posting)
                wordRefs[docId].push_back(wid);
        }
    }
}


void inverted_index::InvertedIndex::fixDictionaryHoles()
{

    addToLog("===> –ê–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥—ã—Ä –≤ –∏–Ω–¥–µ–∫—Å–µ (fixDictionaryHoles) –Ω–∞—á–∞—Ç–æ");

    for (FileId fileId = 0; fileId < docPaths.size(); ++fileId)
    {
        const std::wstring& wpath = docPaths.pathById(fileId);


        if (wpath.empty()) continue;

        // –ü—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∫–∞–∫ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)
        std::ifstream file(wpath, std::ios::binary);
        if (!file.is_open()) continue;

        std::vector<char> data;
        file.unsetf(std::ios::skipws);
        file.seekg(0, std::ios::end);
        size_t fileSize = file.tellg();
        file.seekg(0, std::ios::beg);
        data.reserve(fileSize);

        try {
            data.insert(data.begin(),
                        std::istream_iterator<char>(file),
                        std::istream_iterator<char>());
        } catch (...) { continue; }

        std::stringstream ss;
        std::copy(data.begin(), data.end(), std::ostream_iterator<char>(ss));

        std::set<std::string> realWords;
        auto wordRange = std::ranges::istream_view<std::string>(ss)
                         | std::views::transform([](const std::string& text) {
            auto s = text;
            boost::algorithm::trim_if(s, [](auto c) {
                return OEMtoUpper::iS_not_a_Oem(c) && ispunct(c);
            });
            for (auto& c : s) c = OEMtoUpper::getUpperCharOem(c);
            return s;
        });
        std::ranges::for_each(wordRange, [&realWords](auto&& word) {
            realWords.insert(word);
        });

        std::lock_guard<std::mutex> lock(mapMutex);
        for (const std::string& word : realWords)
        {
            uint32_t wid;
            if (!wordIds.tryGet(word, wid)) continue;

            if (!dictionary[wid].find(fileId)) {
                dictionary[wid][fileId] = 1; // –∏–ª–∏ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π cnt, –µ—Å–ª–∏ –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å
                wordRefs[fileId].push_back(wid);
                addToLog("AUTOFIX: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª —Å–ª–æ–≤–æ '" + word + "' –¥–ª—è —Ñ–∞–π–ª–∞ " + std::to_string(fileId));
            }
        }
    }

    addToLog("===> –ê–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥—ã—Ä –≤ –∏–Ω–¥–µ–∫—Å–µ (fixDictionaryHoles) –∑–∞–≤–µ—Ä—à–µ–Ω–æ");
}


void inverted_index::InvertedIndex::saveIndex() const {

    const_cast<InvertedIndex*>(this)->rebuildDictionaryFromChunks();

    std::ofstream ofs("inverted_index3.dat", std::ios::binary);
    if (ofs.is_open()) {
        boost::archive::binary_oarchive oa(ofs);
        oa << *this;
        ofs.close();
    } else {
        addToLog("Failed to open file for saving index.");
    }

    dictionary.clear();
    dictionary.shrink_to_fit();

}

inverted_index::InvertedIndex::~InvertedIndex() {
    saveIndex();
}

inverted_index::InvertedIndex::InvertedIndex(boost::asio::io_context& io, boost::asio::io_context& io_commit)
        : io_(io)
        , io_commit_(io_commit)
        , strand_(boost::asio::make_strand(io_commit_))
{


        // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞ —Å –∏–Ω–¥–µ–∫—Å–æ–º
        if (std::filesystem::exists("inverted_index3.dat")) {
            // –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            std::ifstream ifs("inverted_index3.dat", std::ios::binary);
            if (ifs.is_open()) {
                boost::archive::binary_iarchive ia(ifs);
                ia >> *this; // –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Boost.Serialization
            }

            dictionary.clear();
            dictionary.shrink_to_fit();

        }

}

void inverted_index::InvertedIndex::compact()
{
    // –í–Ω–µ—à–Ω–∏–π –≤—ã–∑–æ–≤ compact() –¥–æ–ª–∂–µ–Ω –ª–∏—à—å –ø–æ—Å—Ç–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É –≤ strand.
    boost::asio::post(strand_, [this]()
    {
        addToLog("COMPACT: started in strand");

        size_t holes = 0;
        for (const auto& post : dictionary)
            if (post.empty())
                ++holes;

        size_t dict_size = dictionary.size();
        double hole_percent = (dict_size > 0) ? (holes * 100.0 / dict_size) : 0.0;

        std::ostringstream oss;
        oss << "COMPACT: holes=" << holes
            << ", dict_size=" << dict_size
            << ", hole_percent=" << std::fixed << std::setprecision(2)
            << hole_percent << "%";

        // –ù—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–≤–æ–¥–∏—Ç—å compact?
        if (holes == 0 || holes < dict_size / 10)
        {
            oss << " ‚Üí SKIP";
            addToLog(oss.str());
            return;
        }

        oss << " ‚Üí RUN";
        addToLog(oss.str());

        // === 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã ===
        std::vector<PostingList> newDict;
        newDict.reserve(dictionary.size() - holes);

        std::unordered_map<uint32_t, uint32_t> remap; // oldWid ‚Üí newWid

        // wordIds –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –Ω–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        std::unordered_map<std::string, uint32_t> new_word2id;
        std::vector<std::string> new_id2word;

        for (uint32_t oldWid = 0; oldWid < dictionary.size(); ++oldWid)
        {
            auto& post = dictionary[oldWid];
            if (post.empty())
                continue; // –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—ã—Ä–∫—É

            auto newWid = static_cast<uint32_t>(newDict.size());
            remap[oldWid] = newWid;
            newDict.push_back(std::move(post));

            const std::string& word = wordIds.byId(oldWid);
            new_word2id[word] = newWid;
            new_id2word.push_back(word);
        }

        // –ü–µ—Ä–µ—Å—Ç–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞—Ä—å
        dictionary.swap(newDict);

        // === 2. –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ wordIds ===
        wordIds.rebuild(std::move(new_word2id), std::move(new_id2word));

        // === 3. –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ wordRefs ===
        for (auto& [fileId, vec] : wordRefs)
        {
            for (uint32_t& wid : vec)
            {
                wid = remap.at(wid);
            }
        }

        addToLog("COMPACT: done");
    });
}

void inverted_index::InvertedIndex::safeEraseFile(FileId fileId)
{
    /*  –¥–ª—è –∫–∞–∂–¥–æ–π Wid-–æ—á–µ—Ä–µ–¥–∏ —Å—Ç–∏—Ä–∞–µ–º –∑–∞–ø–∏—Å—å hash, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
        (–Ω–∏–∫–∞–∫–∏—Ö erase –ø–æ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É –∏–Ω–¥–µ–∫—Å—É)  */

    boost::asio::post(strand_,[this,fileId]()
    {
        safeEraseFileInternal(fileId);
    });

}

bool inverted_index::InvertedIndex::enqueueFileUpdate(const std::wstring& path)
{
    namespace fs = std::filesystem;

    std::wcout << L"[enqueueFileUpdate] Request for path: " << path << std::endl;

    if (!fs::exists(path) || !fs::is_regular_file(path))
    {
        std::wcout << L"[enqueueFileUpdate] Skip ‚Äî not a regular file: " << path << std::endl;
        return false;
    }

    // –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á–∏—Ç–∞–µ–º –≤ –ª—é–±–æ–º –ø–æ—Ç–æ–∫–µ
    fs::file_time_type ts = fs::last_write_time(path);
    uint64_t sz = fs::file_size(path);

    //
    // –†–∞–±–æ—Ç–∞ —Å docPaths –∏ —É–¥–∞–ª–µ–Ω–∏–µ ‚Äî —Å—Ç—Ä–æ–≥–æ –≤ strand
    //
    boost::asio::post(strand_,
                      [this, path, ts, sz]()
                      {
                          std::wcout << L"[strand/docPaths] Upserting: " << path << std::endl;

                          auto [fileId, changed] = docPaths.upsert(path, ts, sz);

                          if (!changed)
                          {
                              std::wcout << L"[strand/docPaths] File unchanged ‚Äî stopping update.\n";
                              return;
                          }

                          bool isNewFile = (wordRefs.find(fileId) == wordRefs.end());

                          if (!isNewFile)
                          {
                              std::wcout << L"[strand/index] Old file changed, erasing old postings...\n";
                              safeEraseFileInternal(fileId);
                          }
                          else
                          {
                              std::wcout << L"[strand/index] New file detected, skipping erase.\n";
                          }

                          //
                          // ---- –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–º–∏—Å –∏ future –î–õ–Ø –≠–¢–û–ì–û –ö–û–ù–ö–†–ï–¢–ù–û–ì–û –§–ê–ô–õ–ê ----
                          //
                          auto promise = std::make_shared<std::promise<void>>();
                          auto future  = promise->get_future();

                          // –ó–¥–µ—Å—å –ø–æ –∂–µ–ª–∞–Ω–∏—é –º–æ–∂–Ω–æ future —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ç–≤–æ—ë–º –º–µ–Ω–µ–¥–∂–µ—Ä–µ
                          // –∏–ª–∏ –≤–µ—Ä–Ω—É—Ç—å –Ω–∞—Ä—É–∂—É, –µ—Å–ª–∏ enqueueFileUpdate –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å future.
                          // –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–∞–∫, future –±—É–¥–µ—Ç —É–Ω–∏—á—Ç–æ–∂–µ–Ω ‚Üí –Ω–æ—Ä–º–∞–ª—å–Ω–æ.

                          //
                          // ---- –ó–∞–ø—É—Å–∫–∞–µ–º –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Ñ–∞–π–ª–∞ ----
                          //
                          std::wcout << L"[strand/index] Scheduling fileIndexing job for id=" << fileId << std::endl;

                          boost::asio::post(io_, [this, fileId, promise]()
                          {
                              try
                              {
                                  std::wcout << L"[fileIndexing] Started for id=" << fileId << std::endl;

                                  // üî• –í–ê–ñ–ù–û: fileIndexing —Ç–µ–ø–µ—Ä—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç promise
                                  fileIndexing(fileId, promise);

                                  std::wcout << L"[fileIndexing] Dispatched batch for id=" << fileId << std::endl;
                              }
                              catch (...)
                              {
                                  std::wcerr << L"[fileIndexing EXC] id=" << fileId << std::endl;
                                  try { promise->set_exception(std::current_exception()); } catch(...) {}
                              }
                          });

                          //
                          // –¢–µ–ø–µ—Ä—å fileIndexing ‚Üí —Å–æ–∑–¥–∞—ë—Ç batch ‚Üí batch.promise = promise
                          // ‚Üí processBatch –∑–∞–≤–µ—Ä—à–∏—Ç promise->set_value() –∏–ª–∏ set_exception()
                          //
                      });

    return true;
}


bool inverted_index::InvertedIndex::enqueueFileDeletion(const std::wstring& path)
{
    std::wcout << L"[enqueueFileDeletion] Request for path: " << path << std::endl;

    FileId id;

    {
        std::lock_guard<std::mutex> lock(mapMutex); // —Ç–æ–ª—å–∫–æ –¥–ª—è tryGetId, –µ—Å–ª–∏ –æ–Ω–æ —Ç—Ä–µ–±—É–µ—Ç
        if (!docPaths.tryGetId(path, id))
        {
            std::wcout << L"[enqueueFileDeletion] Skip ‚Äî unknown file: " << path << std::endl;
            return false;
        }
    }

    // –ø–æ–º–µ—á–∞–µ–º —Ñ–∞–π–ª –∫–∞–∫ —É–¥–∞–ª—ë–Ω–Ω—ã–π
    boost::asio::post(strand_, [this, id, path]() {

        std::wcout << L"[strand/docPaths] markRemoved: " << path << L" (id=" << id << L")" << std::endl;
        docPaths.markRemoved(id);

    });

    // —á–∏—Å—Ç–∏–º –ø–æ—Å—Ç–∏–Ω–≥–∏ –∏ wordRefs
    boost::asio::post(strand_, [this, id]() {

        std::wcout << L"[strand/dictionary] Starting cleanup for id=" << id << std::endl;

        auto refIt = wordRefs.find(id);
        if (refIt == wordRefs.end()) {
            std::wcout << L"[strand/dictionary] Already removed, id=" << id << std::endl;
            return;
        }

        const auto &widList = refIt->second;

        for (uint32_t wid : widList)
        {
            const size_t chunkIndex = wid / CHUNK_SIZE;
            const size_t localIndex = wid % CHUNK_SIZE;

            if (chunkIndex >= dictionaryChunks.size())
                continue;

            auto& chunkPtr = dictionaryChunks[chunkIndex];
            if (!chunkPtr)
                continue;

            Chunk& chunk = *chunkPtr;
            std::unique_lock<std::shared_mutex> lk(chunk.mutex);

            auto& posting = chunk.bucket[localIndex];
            posting.erase(id);
            // –µ—Å–ª–∏ –ø—É—Å—Ç–æ–π ‚Äî –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞—ë—Ç—Å—è –ø—É—Å—Ç—ã–º; —á–∏—Å—Ç–∏—Ç—å –µ—â—ë –≥–¥–µ-—Ç–æ –Ω–µ –Ω–∞–¥–æ
        }

        std::wcout << L"[strand/dictionary] Cleaned "
                   << widList.size() << L" postings for id=" << id << std::endl;

        auto it = wordRefs.find(id);
        if (it != wordRefs.end()) {
            wordRefs.erase(it);
            std::wcout << L"[strand/wordRefs] Erased id=" << id << std::endl;
        } else {
            std::wcout << L"[strand/wordRefs] Already erased id=" << id << std::endl;
        }
    });

    return true;
}
